# mysql笔记、

https://www.cnblogs.com/wenxiaofei/p/9853682.html【数据库面试题】

### 数据库的三大范式

**第一范式（1NF）**：要求数据库表的每一列都是不可分割的最小数据单元。【确保每列保持原子性】

**第二范式（2NF）**：在1NF的基础上，非主键属性必须**完全依赖**于主键（确保表中的每列都和主键相关）。

**第三范式（3NF）：**在第二范式的基础上更进一层,目标是**确保每列都和主键列直接相关,而不是间接相关。**

### 关系数据库和非关系数据库

非关系型数据库的优势：

1.性能NOSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。

2.可扩展性同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。

关系型数据库（mysql）的优势：

1.复杂查询可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。

2.事务支持使得对于安全性能很高的数据访问要求得以实现。

## 一.Innodb引擎和MyIASM引擎

区别：

1. MyIASM是非事务安全的，而InnoDB是事务安全的
2. MyIASM锁的粒度是表级的，而InnoDB支持行级锁
3. MyIASM不支持外键，InnoDB支持外键
4. MyIASM支持全文类型（FullText）索引，而InnoDB不支持全文类型索引
5. MyIASM保存了表的行数，InnDB没有保存表的行数
6. MyIASM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyIASM

应用场景：

1、InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量insert和update操作，应该选择InnoDB

2、MyIASM管理非事务表，提供高速存储和检索以及全文搜索能力，如果再应用中执行大量select操作，应该选择MyIASM

3、对于一般的Web应用来说，应该选择MyIASM，效率更高，特定场景再用InnoDB。

## 二.InnoDB体系结构

InnoDB存储引擎有多个内存块，可以认为这些内存快组成了一个大的内存池，它们负责：

1、维护多有进程/线程需要访问的多个内部数据结构

2、缓存磁盘上的数据，方便快速读取，同时在对磁盘文件的数据修改之前在这里做缓存。

3、重做日志（redo log) 缓冲。

### 2.1.缓存池

![3](D:\笔记图片\3.png)

 缓冲池是通过LRU算法来进行算法管理的。缓冲池中页的大小默认为16KB。InnoDB存储引擎对传统的LRU算法做了一些优化，新访问的页不是直接放入到LRU列表的首部，**而是放在LRU列表的midpoint位置**。

 主要是：为了防止数据的扫描操作，使页大批量的更新，导致，热点页被替换调

LRU中对于脏页的管理：

   数据库会通过CHECKPOINT机制将脏页刷新回磁盘。

   脏页既存在在Flush列表中，也存在于LRU列表中。

   FLUSH列表用来负责刷新，LRU列表用来管理缓冲池中的可用性。

### 2.2.Checkpoint技术

#### 2.3插入缓冲

1.insert buffer

数据页的存放是按照主键进行顺序存放的，**但是对于非聚集索引叶子节点的插入不是顺序存放的，这回导致离散的访问非聚集索引页，由于随机读取的存在，这会导致插入操作性能下降【主要解决的问题】。**

插入缓冲,并不是缓存的一部分,而是物理页,对于非聚集索引的插入或更新操作,不是每一次直接插入索引页.而是先判断插入的非聚集索引页是否在缓冲池中.如果在,则直接插入,如果不再,则先放入一个插入缓冲区中.然后再以一定的频率执行插入缓冲和非聚集索引页子节点的合并操作.

Insert Buffer的使用时间满足两个条件：

 索引是辅助索引

 索引不是唯一的

insert buffer【内部也是用一个B+树实现的】

#### 2.3.1UUID作为主键分析

在存储和检索的时候，innodb会对主键进行物理排序，这对auto_increment_int是个好消息，因为后一次插入的主键位置总是在最后。

但是对uuid来说，这却是个坏消息，因为uuid是杂乱无章的，每次插入的主键位置是不确定的，可能在开头，也可能在中间，在进行主键物理排序的时候，**势必会造成大量的 IO操作影响效率**，在数据量不停增长的时候，特别是数据量上了千万记录的时候，读写性能下降的非常厉害。而且会导致存在大量的碎片问题。

#### 2.4两次写

主要是用保证数据库 的的可靠性

1.部分也失效问题

InnoDB的Page Size一般是16KB，将数据写入到磁盘是以Page为单位进行操作的。16K的数据，写入4K时，发生了系统断电/os crash ，只有一部分写是成功的，这种情况下就是partial page write问题。

2.两次写的实现

doublewrite由两部分组成，一部分为内存中的doublewrite buffer，其大小为2MB，另一部分是磁盘上共享表空间(ibdata x)中连续的128个页，即2个区(extent)，大小也是2M

​	1、当一系列机制触发数据缓冲池中的脏页刷新时，并不直接写入磁盘数据文件中，而是先拷贝至内存中的doublewrite buffer中；

　　2、接着从两次写缓冲区分两次写入磁盘共享表空间中(连续存储，顺序写，性能很高)，每次写1MB；

　　3、待第二步完成后，再将doublewrite buffer中的脏页数据写入实际的各个表空间文件(离散写)；(脏页数据固化后，即进行标记对应doublewrite数据可覆盖)。

![img](https://img2018.cnblogs.com/blog/780228/201909/780228-20190922000801124-2040747364.png)

作用：

在数据库启动时（异常关闭的情况下），都会做数据库恢复（redo）操作。在恢复的过程中，数据库会检查页面是否合法（校验），如果发现一个页面的校验结果不一致，则此时就会用到两次写机制，用两次写空间中的数据来恢复异常页面的数据，这也正是为处理这样的错误而设计的。

## 三.索引

### 1.索引的优缺点

**优点** ：

- 使用索引可以大大加快 数据的检索速度（大大减少的检索的数据量）, 这也是创建索引的最主要的原因。
- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。

**缺点** ：

- 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。
- 索引需要使用物理文件存储，也会耗费一定空间。

但是，**使用索引一定能提高查询性能吗?**

大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。

### 2.索引的实现

#### 1.使用B+树 的原因。为什么没有才有用Hash索引？

mysql没有采用的hash索引的原因：

hash索引只存储哈希值和行指针

1.hash冲突【会导致储存引擎必须遍历所以有航指针，逐行比较】

2.Hash 索引不支持 顺序 和 范围查询 (Hash 索引不支持顺序和范围查询是它最大的缺点【因为哈希索引始终是是要用全部字段进行查找】

3.hash索引只支持等值查询。

#### 2.B+树和B树

- B树和B+树这两种实现方式是最常见的，B树、B+树都是平衡树。
- MySQL的Innodb用B+树做索引。
- MySQL的MyISAM的索引有两种，主索引和辅助索引，主索引使用具有唯一性的键值，辅助索引键值可以重复。和Innodb不同的是，最后的叶子节点存的是地址，而Innodb最后的叶子节点存的是完整的数据。

B树和B+树的区别

- B+ 树的磁盘读写更低，因为非叶子节点可以存储更多的索引 key，而 key 索引在同一层更集中，那么会降低磁盘 IO 读写次数。
- B+ 树的查询效率更稳定，任何查询都必须从根节点到叶子节点，路径是相似的，所以更稳定（最好最坏都在底层）。
- 区间访问友好性，MySQL 是关系型数据库，所以经常会按照区间来访问某个索引，**B+ 树的叶子节点会按照顺序建立起链状指针**，增强了区间访问性。

#### 3.索引类型

##### 1、主键索引

数据表的主键列使用的就是主键索引。

一张数据表有只能有一个主键，并且主键不能为 null，不能重复。

在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。

##### 2、二级索引

**二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。**

唯一索引，普通索引，前缀索引等索引属于二级索引。

1. **唯一索引(Unique Key)** ：唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。** 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。

2. **普通索引(Index)** ：**普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。**

3. **前缀索引(Prefix)** ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。

4. **全文索引(Full Text)** ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。

   【**原理**：是先定义一个词库，然后在文章中查找每个词条(term)出现的频率和位置，把这样的频率和位置信息按照词库的顺序归纳，这样就相当于对文件建立了一个以词库为目录的索引，这样查找某个词的时候就能很快的定位到该词出现的位置】 分词系统

   全文索引没有提供一个可供选择的排序算法【无法基于相对位置进行位置排序】 同时只有全文索引全部在内存的时候 效率很高。 全文索引还有影响优化器的工作，使其并不是按照你的预期进行工作的。

##### 3.聚集索引与非聚集索引

**1.聚集索引**

InnoDB存储引擎是索引组织表，表中的数据按照主键顺序存放。聚集索引就是按照每张表的主键构建一棵B+树，叶子节点中存放的是整张表的行记录数据，即数据页。

B+树中，聚集索引存储不是在物理上连续的，但是在逻辑上是连续的

缺点：

1. **依赖于有序的数据** ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。

2. **更新代价大** ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改， 而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的， 所以对于主键索引来说，主键一般都是不可被修改的。

**2.辅助索引**

辅助索引（非聚集索引），叶子记录并不包涵行记录的全部数据。叶子节点除了包涵键值外，每个叶子除了包涵键值还包涵了一个书签（bookmark）,该书签用来是相应行数据的聚集索引键（这里是索引键，所以仍然需要在查询一次聚集索引，得到最终的数据）。

##### **4.联合索引**

联合索引对表上的多个列进行索引。

**为什么，要建联合索引？**

建了一个(a,b,c)的复合索引，那么实际等于建了(a),(a,b),(a,b,c)三个索引，因为每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，这可是不小的开销！

##### **5.覆盖索引**

覆盖索引指：从辅助索引中就可以得到查询的记录，不需要查询聚集索引中的记录。 好处是：辅助索引不包含整行记录，故其大小要远小于聚集索引，可以减少大量的IO操作。

##### 6.普通索引和唯一索引区别和选择

**1.查询过程**

例如：

select id from T where k=5

普通索引：检索到k = 5的节点后，会继续检索后面的节点，知道检索到不是k=5为止，

唯一索引：检索到k=5后，立即返回，因为是唯一的索引节点。

虽然两者索引的个数不一样，但是InnoDB是以数据页来存储数据的，所以基本上查询到的第一条K=5和后面的K=5都在同一页上，避免再次在磁盘寻址

##### 2.更新过程

提示：现在的InnoDB中，现在是有change buffer这块内存缓冲区的。

对于所有的唯一索引来说，所有的更新操作，都违反了唯一约束的特性，所以所有的更新操作change buffer 都不起作用

只有普通索引可以使用。

更新操作在change buffer内存中有数据时：

1.唯一索引和普通索引都直接在内存修改

更新操作在change buffer内存中没有数据时：

1.唯一索引：此时需要在磁盘盘中读取数据页

2.普通索引：直接把更新的数据写在change buff 中就可以了



### 3.如何添加索引？

原则：尽量使用索引项更小

1.直接创建完整索引，这样可能比较浪费空间

2.创建前缀索引，节省空间，但是会增加查询扫描次数，并且不能使用覆盖索引

3.倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题

4.创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，与方式3都不支持范围扫描



### 4.什么时候不建议使用索引

1. 数据唯一性差的字段不要使用索引：比如性别，只有两种可能数据。意味着索引的二叉树级别少，多是平级。这样的二叉树查找无异于全表扫描。
2. 频繁更新的字段不要使用索引：比如logincount登录次数，频繁变化导致索引也频繁变化，增大数据库工作量，降低效率。
3. 字段不在where语句出现时不要添加索引：只有在where语句出现，mysql才会去使用索引
4. 数据量少的表不要使用索引：使用了改善也不大
5. 另外，如果mysql估计使用全表扫描要比使用索引快，则不会使用索引。





只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！

**表级锁**：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高 ，并发度最低。

**页面锁**：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

**行级锁**：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。





## 四.锁

难点：最大程度地利用数据库的并发访问，同时确保每个用户能以一致的方式读取和修改数据。

### **4.1.MyISAM 和 InnoDB 存储引擎使用的锁：**

- MyISAM 采用表级锁(table-level locking)。
- InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁

### 4.2.InnoDB存储引擎中的锁

- Record lock：单个行记录上的锁
- Gap lock：间隙锁，锁定一个范围，不包括记录本身
- Next-key lock：record+gap 锁定一个范围，包含记录本身【解决幻读】

### 4.3.InnoDB中锁的类型

1、共享锁：允许事务读一行数据。S  Lock

2、排他锁：允许事务删除或更新一行数据。  X  Lock。

意向共享锁：事务想要获取一张表中某几行的共享锁

意向排他锁：事务想要获取一张表中某几行的排他锁

### 4.4.InnoDB一致性非锁定读

一致性**非锁定读**是指 InnoDB存储引擎通过 行多版本控制[**MVCC多版本**] 的方式来读取当前执行时间数据库中行的数据。

如果读取的行正在努执行delete 或update操作，这时读取操作不会因此去等待行上锁的释放。相反的，InnoDB存储引擎回去读取行的一个**快照数据**。

之所以称其为非锁定读，因为不需要等待访问的行上X锁(排他锁）的释放。**快照数据是指该行的之前版本的数据**，该实现是通过undo段来完成。而undo用来在事务中回滚数据，因此快照数据本身是没有额外的开销。此外，快照数据是不需要上锁的，因为没有事务需要对历史的数据进行修改操作。

**read commited** 事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的**最新一份快照数据**。 

**repeatable read** 事务隔离级别下，于快照数据，非一致性读总是读取事务开始时的行数据版本。

### 4.5一致性锁定读

### 4.6 解决幻读问题

在默认的事务隔离级别下，即 repeatable read下，InnoDB存储引擎采用 Next-Key Locking机制来避免幻读问题。这点可能不同于其他的数据库，如oracle数据库，因为其可能需要在 selializable 的事务隔离级别下才能解决幻读。

Phantom Problem是指在同一事务下，连续两次执行相同的SQL语句可能会导致不同的结果，第二次的SQL语句可能会**返回之前不存在的行**。

例如表由1、2、5这三个值组成，若事务T1执行如下SQL语句：

```sql
SELECT * FROM t WHERE p > 2 FOR UPDATE;
```

此时事务T1并没有进行提交操作，上述应该返回 5这个结果。

若此时，另一个事物T2插入了4这个值，并且数据库运行该操作，那么事务T1再次执行上述语句，返回结果是4和5。这与第一次得到的结果不同，违反了事务的隔离型，即当前事务能够看到其他事务的结果。

**InnoDB存储引擎采用 Next-Key Locking的算法来避免幻读问题。对于上述语句，其锁住的不是5这单个值，而是对（2，+∞）这个范围加了X锁（排它锁）。因此任何对于这个范围的插入额都是不被允许的，从而避免幻读。**



### **4.5.MVCC实现原理**

应对高并发事务, MVCC 比单纯的加行锁更有效, 开销更小

最大的好处是读写不冲突，只有写于写是冲突的，这个特性可以很大程度上提升性能，避免了脏读

MVCC 在读已提交（Read Committed）和可重复读（Repeatable Read）隔离级别下起作用
MVCC 既可以基于乐观锁又可以基于悲观锁来实现

#### 1.MVCC读分类

快照读：读取的是记录的可见版本（有可能是历史版本），不用加锁。简单的SELECT操作，属于快照读，不加锁。

简单的select操作：select * from table where ?

当前读：读取的是记录的最新版本，并且当前读返回的记录都会加上锁，保证其他记录不会再并发修改这条记录。特殊的读操作（显示加S锁和X锁），插入/更新/删除操作，属于当前读，需要加锁。


```
select * from table where ? lock in share mode;  ————加共享锁

select * from table where ? for update;————加排它锁

insert into table values (…);————加排它锁

update table set ? where ?;————加排它锁
```

**为什么插入/更新/删除操作属于当前读？**

这是因为对于一个UPDATE操作，当UPDATE SQL发送给MySQL之后，MySQL Server会根据where条件，读取第一条满足条件的记录，然后InnoDB会将第一条记录返回，并加锁。当MySQL Server收到这条加锁记录之后，会再发起一个UPDATE请求，更新这条记录。一条记录操作完成之后再读取下一条记录，直到没有满足条件的记录位置。因此在UPDATE操作内部需要包含一个当前读。

DELETE也是一样。

INSERT稍微不同，这是因为INSERT操作可能会触发unique key的冲突检查，也会进行一个当前读。

#### 2.实现过程

- 在可重复读隔离级别下，事务在启动的时候 `拍了个基于整库的快照`，并不需要拷贝数据

InnoDB 中 MVCC 的实现方式为：每一行记录都有两个隐藏列：DATA_TRX_ID、DATA_ROLL_PTR（如果没有主键，则还会多一个隐藏的主键列）。

![在这里插入图片描述](https://img-service.csdnimg.cn/img_convert/a02e83f3c8261a48aa2fb6c634a9d8e4.png#pic_center)


DATA_TRX_ID
记录最近更新这条行记录的事务 ID，大小为 6 个字节

DATA_ROLL_PTR
表示指向该行回滚段（rollback segment）的指针，大小为 7 个字节，InnoDB 便是通过这个指针找到之前版本的数据。该行记录上所有旧版本，在 undo 中都通过链表的形式组织。

DB_ROW_ID
行标识（隐藏单调自增 ID），大小为 6 字节，如果表没有主键，InnoDB 会自动生成一个隐藏主键，因此会出现这个列。另外，每条记录的头信息（record header）里都有一个专门的 bit（deleted_flag）来表示当前记录是否已经被删除。

在多个事务并行操作某行数据的情况下，不同事务对该行数据的 UPDATE 会产生多个版本，然后通过回滚指针组织成一条 Undo Log 链，举例：

![在这里插入图片描述](https://img-service.csdnimg.cn/img_convert/e303ce70ab08451930c82a705e182319.png#pic_center)

查询数据可见性规则

InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在 活跃 的所有事务 ID(活跃 指的就是，启动了但还没提交)

数组里面事务 ID 的最小值记为低水位

系统里面已经创建过的事务 ID 的最大值加 1 记为高水位

视图数组和高水位，就组成了当前事务的一致性视图（read-view）


![在这里插入图片描述](https://img-blog.csdnimg.cn/20210202093720466.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTM3NjM0,size_16,color_FFFFFF,t_70)

规则如下：

一个数据版本的 row trx_id 如果落在绿色部分，这个数据是可见的

一个数据版本的 row trx_id 如果落在红色部分，是不可见的

一个数据版本的 row trx_id 如果落在黄色部分，包括两种情况

若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见

若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见






## 五.事务

### 5.1 ACID

**原子性**：A atomic。事务是一个**不可再分割的工作单元**，事务中的操作要么都发生，要么都不发生。**A向B转账**

**一致性**：C consistency。 指事务将数据从一种状态转变为下一种一致状态。执行事务前后，数据保持一致。例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；

**隔离性**：I isolation。每个读写事务对其它事务能相互分离。

**持久性**：D durablity。 事务一旦提交，其结果是的一定的。即使数据库发生故障也不应该对其有任何影响。

### 5.2事务的隔离级别

1、Read Uncommitted 未提交读：最低级别，只能保证不读取物理上损坏的数据；**可能导致脏读、不可重复读、幻读。**

2、Read committed 已提交读：允许读取并发事务已经提交的数据。可能导致不可重复读、幻读。

3、Repeatable Read 可重复度： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改。**可能导致幻读**。

4、Serializable 可串行化。 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰。



- **脏读（Dirty read）:** 还没提交就读到了。当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为==这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”==，依据“脏数据”所做的操作可能是不正确的。

- **不可重复读（Unrepeatableread）:** ==修改==。指在一个事务内==多次读同一数据==。在这个事务还没有结束时，另一个事务也访问该数据。那么，在==第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样==。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。

- **幻读（Phantom read）:** 新增/删除。幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，==接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，==所以称为幻读。

**不可重复读和幻读区别：**

不可重复读的重点是==修改==，比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于==新增或者删除==比如多次读取一条记录发现记录增多或减少了。

### 5.3事务的实现

**redo log 重做日志。保证事务的原子性、持久性**

**undo log保证一致性**。

#### 5.1三大日志

##### **1.binlog**

`binlog` 用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。`binlog` 是 `mysql`的逻辑日志，并且由 `Server` 层进行记录，使用任何存储引擎的 `mysql` 数据库都会记录 `binlog` 日志。

- **逻辑日志**：可以简单理解为记录的就是sql语句 。
- **物理日志**：`mysql` 数据最终是保存在数据页中的，物理日志记录的就是数据页变更 

`binlog` 是通过追加的方式进行写入的，可以通过 `max_binlog_size` 参数设置每个 `binlog`
文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。

**binlog使用场景**

在实际应用中， `binlog` 的主要使用场景有两个，分别是 **主从复制** 和 **数据恢复** 。

1. **主从复制** ：在 `Master` 端开启 `binlog` ，然后将 `binlog` 发送到各个 `Slave` 端， `Slave` 端重放 `binlog` 从而达到主从数据一致。
2. **数据恢复** ：通过使用 `mysqlbinlog` 工具来恢复数据。

##### **2.redo log**

重做日志用来实现事务的持久性。 **具体来说就是只记录事务对数据页做了哪些修改**

一部分是：一是内存中的重做日志缓冲( `redo log buffer` )，二：重做日志文件`redo log file` )

InnoDB是事务的存储引擎，通过Force Log at Commit机制实现事务的持久性。将事务的所有日志写入到重做日志文件进行持久化。

 `redo log buffer` 写入 `redo log file` 实际上是先写入 `OS Buffer` ，然后再通过系统调用 `fsync()` 将其刷到 `redo log file`【刷盘的性能是影响了数据库的写入性能】

##### **binglog和redo log 的区别**

1.文件大小 | `redo log` 的大小是固定的。 | `binlog` 可通过配置参数 `max_binlog_size` 设置每个`binlog` 文件的大小。 

2.实现方式 |redo log` 是 `InnoDB` 引擎层实现的，并不是所有引擎都有。 | `binlog` 是 `Server` 层实现的，所有引擎都可以使用 `binlog` 日志 |

3.|记录方式  redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。 | binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上 

4.redo log 是物理日志，binglog是逻辑日志。因此在数据恢复的时候 redo log日志速度快。

5.写入磁盘的时间不同。逻辑日志 只有在事务提交的时候才会写入。 而INN0db储存日志是在事务进行中被不断写入的。

##### **3.undo log**

事务的一致性就是靠undo log日志实现的

在事务需要回滚时，这就进行了undo。

undo不是将数据库物理的恢复到了原来的样子，而是逻辑的恢复到了原来的样子。

**原子性** 底层就是通过 `undo log` 实现的。`undo log` 主要记录了数据的逻辑变化，比如一条 `INSERT` 语句，对应一条 `DELETE` 的 `undo log` ，对于每个 `UPDATE` 语句，对应一条相反的 `UPDATE` 的 `undo log` ，这样在发生错误时，就能回滚到事务之前的数据状态。同时， `undo log` 也是 `MVCC`(多版本并发控制)实现的关键

##### 5.4purge

delete和update操作 可能并不是直接删除原来的数据。undo log只是对节点做一个标记。

purge用于最终完成delete和update操作。因为InnoDB存储引擎支持MVCC操作。所以记录不能在事务提交时立即进行处理。这时其他事务可能正在引用该行，故InnoDB存储引擎需要保存记录之前的版本。而是否可以删除该条记录通过purge来进行判断。若该行记录已不被任何其他事务引用，那么就可以进行真正的delete操作

##### 5.5group commit

若事务为非只读事务，则每次事务提交时，需要进行一次fsync操作，以此保证重做日志都已经写入磁盘。当数据库发生宕机时，可以通过重做日志进行恢复。虽然固态硬盘的出现提高了磁盘的性能，然而磁盘的fsyns性能是有限的。

​		为了减少fsync操作的次数，提高效率，当前主流的数据库都提供了group commit 功能，一次fsync可以刷新确保多个事务日志被写入文件。









## 六.explain详解

https://blog.csdn.net/oneby1314/article/details/107938325

1. 表的读取顺序（id 字段）
2. 数据读取操作的操作类型（select_type 字段）
3. 哪些索引可以使用（possible_keys 字段）
4. 哪些索引被实际使用（keys 字段）
5. 表之间的引用（ref 字段）
6. 每张表有多少行被优化器查询（rows 字段）

```mysql
mysql> explain select * from tbl_emp;
+----+-------------+---------+------+---------------+------+---------+------+------+-------+
| id | select_type | table   | type | possible_keys | key  | key_len | ref  | rows | Extra |
+----+-------------+---------+------+---------------+------+---------+------+------+-------+
|  1 | SIMPLE      | tbl_emp | ALL  | NULL          | NULL | NULL    | NULL |    8 | NULL  |
+----+-------------+---------+------+---------------+------+---------+------+------+-----
```

###### **1.id**：

select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序

###### **2.select_type**：

查询的类型，主要用于区别普通查询、联合查询、子查询等复杂查询

SIMPLE：简单的select查询，查询中不包含子查询或者UNION
PRIMARY：查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY
SUBQUERY：在SELECT或者WHERE列表中包含了子查询
DERIVED：在FROM列表中包含的子查询被标记为DERIVED（衍生）MySQL会递归执行这些子查询，把结果放在临时表里
UNION：若第二个SELECT出现在UNION之后，则被标记为UNION；若UNION包含在FROM子句的子查询中，外层SELECT将被标记为：DERIVED
UNION RESULT：从UNION表获取结果的SELECT

###### 3.type【重要】

访问类型排列，显示查询使用了何种类型【关键】

1.type显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是：system>const>eq_ref>ref>fultext>ref_or_null>index_merge>unique_subquery>index_subquery>range>index>ALL
**2.挑重要的来说：system>const>eq_ref>ref>range>index>ALL，一般来说，得保证查询至少达到range级别，最好能达到ref。**

1.system：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现，这个也可以忽略不计

2.const：表示通过索引一次就找到了，const用于比较primary key或者unique索引。因为只匹配一行数据，所以很快。如将主键置于where列表中，MySQL就能将该查询转换为一个常量

3.eq_ref：唯一性索引，对于每个索引键，表中只有一条记录与之匹配，常见于主键或唯一索引扫描

4.ref：非唯一索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体

**5.range**：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引一般就是在你的where语句中出现了`between`、`<`、`>`、`in`等的查询这种范围扫描索引扫描比全表扫描要好，因为他**只需要开始索引的某一点，而结束于另一点，不用扫描全部索引**

6.**index**：Full Index Scan，index与ALL区别为index类型**只遍历索引树**。这通常比ALL快，因为索引文件通常比数据文件小。（也就是说**虽然all和index都是读全表，但index是从索引中读取的，而all是从硬盘数据库文件中读的**）

7.**all**：FullTable Scan，**将遍历全表以找到匹配的行（全表扫描）**

###### 4.key

实际使用的索引，如果为null，则没有使用索引

**若查询中使用了覆盖索引，则该索引仅出现在key列表中**

###### 5.key_len

1.表示索引中使用的字节数，尽量长度越短越好

2.为索引的最大可能的长度，并非实际使用的长度。

###### 6.ref

1.显示索引哪一列被使用了，最好是一个常数

###### 7.Extra：【重要】

包含不适合在其他列中显示但十分重要的额外信息

**1.Using filesort（文件排序）**

MySQL中无法利用索引完成排序操作成为“文件排序”

说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。出现这种情况表示不好。一定要优化sql

2.**Using temporary（创建临时表）**

使用了临时表保存中间结果，MySQL在对查询结果排序时使用临时表。常见于排序 order by 和分组查询 group by

出现 Using temporary 超级不好（十死无生），需要立即优化 SQL

3.**Using index（覆盖索引）**:表示相应的select操作中是用了覆盖索引

如果要使用覆盖索引，一定要注意select列表中只取出需要的列，不可select *   。因为如果将所有字段一起做索引会导致索引文件过大，查询性能下降。

**4.Using where**：表明使用了where过滤

**5.Using join buffer**：表明使用了连接缓存

##### **MySQL慢查询怎么解决?**

> - slow_query_log 慢查询开启状态。【开启慢查询日志。记录超过多少秒 是属于慢查询，然后用explain进行分析】
> - slow_query_log_file 慢查询日志存放的位置（这个目录需要MySQL的运行帐号的可写权限，一般设置为MySQL的数据存放目录）。
> - long_query_time 查询超过多少秒才记录。

**常见优化查询的一些方法**

1.将一个大的查询分解为多个小查询是很有必要的。

2.只返回必要的列  不适用select*语句

3.只返回必要的行，使用LIMIT语句限制返回的数据‘

**数据库表的优化：**

- 选择合适的**数据类型**：尽可能不要存储NULL字段；使用简单的数据类型（int, varchar/ text）；
- 表的**水平切分**（Sharding）：将同一个表中的记录拆分到多个结构相同的表中（策略：哈希取模；根据ID范围来分）。当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力；
- 表的**垂直切分**：将一张表按列切分成多个表。可以将不常用的字段单独放在同一个表中；把大字段独立放入一个表中；或者把经常使用的字段（关系密切的）放在一张表中。垂直切分之后业务更加清晰，系统之间整合或扩展容易，数据维护简单

**系统配置的优化操作系统**：增加TCP支持的队列数；MySQL配置文件优化：缓存池大小和个数设置

**硬件的优化磁盘性能**：固态硬盘；CPU：多核且高频；内存：增大内存



## 七.主从同步

#### 1. 主从集群

MySQL 主从集群带来的作用是：

1、提高数据库负载能力，主库执行读写任务（增删改），备库仅做查询。

2、提高系统读写性能、可扩展性和高可用性。

3、数据备份与容灾，备库在异地，主库不存在了，备库可以立即接管，无须恢复时间。

#### 2. 主从同步

##### 7.2.1 binlog是什么？有什么作用？

全名binary log，一种日志文件，逻辑日志。保存了Mysql服务器实例上数据修改的日志信息，包含全量的mysql增删改查数据。

用于主从复制，在主从结构中，binlog 作为操作记录从 master 被发送到 slave，slave服务器从 master 接收到的日志保存到 relay log 中。

用于数据备份，在数据库备份文件生成后，binlog保存了数据库备份后的详细信息，以便下一次备份能从备份点开始。

#### 3. 主从复制

mysql主从复制需要三个线程：master（binlog dump thread）、slave（I/O thread 、SQL thread）

**binlog dump线程**：主库中有数据更新时，根据设置的binlog格式，将更新的事件类型写入到主库的binlog文件中，并创建log dump线程通知slave有数据更新。当I/O线程请求日志内容时，将此时的binlog名称和当前更新的位置同时传给slave的I/O线程。

**I/O线程**：该线程会连接到master，向log dump线程请求一份指定binlog文件位置的副本，并将请求回来的binlog存到本地的relay log中。

**SQL线程**：该线程检测到relay log有更新后，会读取并在本地做redo操作，将发生在主库的事件在本地重新执行一遍，来保证主从数据同步。

![image-20210505162349072](D:/wendang/wechatdownload/WeChat Files/wxid_3266912668914/FileStorage/File/2021-05/mysql高级zy/mysql高级zy/mysql高级.assets/image-20210505162349072-0616962.png)



一句话解释：

**Slaver读取Master的binlog并顺序执行**

概述：

- MySQL的主从复制是一个异步的复制过程（虽然一般情况下感觉是实时的），在Master与Slave之间实现整个主从复制的过程是由三个线程参与完成的。其中有两个线程（SQL线程和IO线程）在Slave端，另一个线程（I/O线程）在Master端。
- 要实现MySQL的主从复制，首先必须打开Master端的binlog记录功能，否则就无法实现。因为整个复制过程实际上就是Slave从Master端获取binlog日志，然后再在Slave上以相同顺序执行获取的binlog日志中的记录的各种SQL操作



**详细过程**

1. 在Slave 服务器上执行start slave命令开启主从复制开关，开始进行主从复制。
2. 此时，Slave服务器的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change     master命令指定的）之后开始发送binlog日志内容
3. Master服务器接收到来自Slave服务器的IO线程的请求后，其上负责复制的IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在Master服务器端记录的IO线程。返回的信息中除了binlog中的下一个指定更新位置。
4. Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容。
5. Slave服务器端的SQL线程会实时检测本地Relay   Log 中新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点



知识点

1. 3个线程，主库IO，从库IO和SQL及作用
2. master.info（从库）作用
3. relay-log 作用
4. 异步复制
5. binlog作用（如果需要级联需要开启Binlog）

relay log: 

   在主服务器读取的二进制事件然后Slave I/O线程写入到该文件，生成该文件。

该文件中的事件会被SQL thread 执行一次。

master info log:

   该文件包含状态信息、从服务器连接到主服务器的配置信息。如:主服务器

 名称、IP、连接账号、密码、日志文件名称、日志位置坐标、端口号等信息。

relay log info log:

   主要包含中继日志执行位置的状态信息。

#### 4.怎么减少主从延迟

- 降低多线程大事务并发的概率，优化业务逻辑
- 优化SQL，避免慢SQL，减少批量操作，建议写脚本以update-sleep这样的形式完成。
- 提高从库机器的配置，减少主库写binlog和从库读binlog的效率差。
- 尽量采用短的链路，也就是主库和从库服务器的距离尽量要短，提升端口带宽，减少binlog传输的网络延时。
- 实时性要求的业务读强制走主库，从库只做灾备，备份。

、







## 八.数据库优化

### 1.读写分离

![img](https://img2.baidu.com/it/u=3866159327,2844035182&fm=26&fmt=auto&gp=0.jpg)

优点：

可以避免单点故障

负载均衡，对于数据库读能力的拓展

挑战：

1.对sql类型判断，是读（select）走从库，是写（insert、update、delete）走主库

2.主从数据的同步延时问题：对于强一致的业务，读写都强制走主库

3.事务问题：如果同一事务中，因读写分离，导致跨了多个库，那么jdbc将无法控制，属于分布式事务（效率低）范畴。所以，现在对于事务中夸库的情景，都同一走主库。

4.高可用：

新增slave节点：

slave宕机：

master宕机：进行主从切换

### 2.分库分表

**垂直分表**：可以把一个宽表的字段按访问频次、是否是大字段的原则拆分为多个表，这样既能使业务清晰，还能提升部分性能。拆分后，尽量从业务角度避免联查，否则性能方面将得不偿失。

**垂直分库**：可以把多个表按业务耦合松紧归类，分别存放在不同的库，这些库可以分布在不同服务器，从而使访问压力被多服务器负载，大大提升性能，同时能提高整体架构的业务清晰度，不同的业务库可根据自身情况定制优化方案。但是它需要解决跨库带来的所有复杂问题。

**水平分库**：可以把一个表的数据(按数据行)分到多个不同的库，每个库只有这个表的部分数据，这些库可以分布在不同服务器，从而使访问压力被多服务器负载，大大提升性能。它不仅需要解决跨库带来的所有复杂问题，还要解决数据路由的问题(数据路由问题后边介绍)。

**水平分表**：可以把一个表的数据(按数据行)分到多个同一个数据库的多张表中，每个表只有这个表的部分数据，这样做能小幅提升性能，它仅仅作为水平分库的一个补充优化。

1.分库的优点：

```
降低单台机器的负载压力，提升写入性能。（提供了多机器实现写的能力）
```

2.分表的优点

```chinese
提高数据操作数据的效率，无论是读写

挑战：

1.基本数据库的增删查改：
sql解析：
sql路由：sql路由包括库路由和表路由，确定插入到那个库或者那个表
sql改写：
sql执行：
结果集的合并：每个sql执行之后，都会有一个执行结果，并对每一个分库分表结果集进行合并，得到一个完整的结果
2.分布式的ID
在分库分表后，我们不能再使用mysql的自增主键。因为在插入记录的时候，不同的库生成的记录的自增id可能会出现冲突。现在用了一个全局的ID生成器

3.动态扩容
指增加分库分表的数量
这种方式可以在扩容时，可以不用数据迁移

4.数据迁移
对于老的数据库，已经有存量的数据，单表已经很大，可以先进行数据迁移
其中的全量同步：
因为mysql的binlog只会保存近几天的更改的数据 
 1.刷新一遍binlog。问题在于，如果表的数据量过大，例如上亿条数据，这种方式可能会造成很大的主从延迟，大量的binlog也会占用大量的磁盘空间。
 
 2.流式读取历史数据。流式读取之前，记录下当前的binlog位置，之后流式分批读取，读取完成之后，把之前记录的binlog位置提供给binlog订阅服务如(puma、databus、canal)等，进行增量同步。

 其中的全量同步：
 
 拉取binlog数据，转化成SQL到目标库上面
```

### 3.mysql是怎么b保证数据不丢？

#### 1.binlog 的写入机制

事务执行过程中，先把日志写入到binlog cache,事务提交的时候，再把 binlog cache 写到 binlog文件中

一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。 这里也涉及binlog cache的保存问题

系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内存大小，超过了规定的大小就占存储到磁盘中，

![1](D:\笔记图片\1.png)

注意：

1.每个线程有自己 binlog cache，公用一份binlog文件

2.图中write,指把日志写入到文件系统的page cache,还没有持久话到日志

3.图中fsync,此时将数据持久化到磁盘

write 和 fsync 的时机，是由参数 sync_binlog控制

a.sync_binlog=0 的时候，表示每次提交事务都只 write

b.sync_binlog=1 的时候，表示每次提交事务都会 write，fsync

c.sync_binlog=N > 1 的时候，表示表示每次提交事务都 write，但累积 N 个事务后才 fsync

对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的binlog事务

#### 2.redo log 的写入机制

<img src="D:\笔记图片\2.png" alt="2" style="zoom:75%;" />

redo log buffer：物理上是在 MySQL 进程内存中，就是图中的红色部分；

写到page cache是write

持久化到磁盘中，hard disk

对比binlog的写入：

为了控制 redo log 的写入策略，InnoDB 提供了innodb_flush_log_at_trx_commit参数，它有三种可能取值：

1.设置为 0 的时候，表示每次事务提交时都只是把 redo log buffer中

2.设置为 1 的时候，表示每次事务提交时都将 redo log持久化到磁盘

3.设置为 2 的时候，表示每次事务提交时都只是把 redo 写到 page cache

InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer中的日志，调用write写到page cache,然后调用fsync 持久化到磁盘。

一种是，redo log buffer 占用的空间即将达到 即将达到 innodb_log_buffer_size 一半，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留文件系统的 page cache。

## 九.相关问题

### 1.mysql中索引和页的关系

​     一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘 I/O 消耗，相对于内存存取，I/O 存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘 I/O 操作次数的渐进复杂度。

  为了达到这个要求 ，磁盘一般都是按需读取。**要求每次都会预读的长度一般为页的整数倍。而且数据库系统将一个节点的大小设为等于一个页，这样每个节点只需要一次 I/O 就可以完全载入。**每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个 node 只需一次 I/O。并把 B-tree 中的 m 值设的非常大，就会让树的高度降低，有利于一次完全载入。

数据库索引组织表 一般是按照 表【MySQL默认会有一个共享表】，段【数据段 索引段【B+叶子结点是保存的数据】等等】，区【一个区是有连续的页组成 一般为1M】  页【磁盘管理的的最小单位，一般默认为16KB】 四个层级

#### **自增主键的问题**

1.自增主键的保存策略

  自增值是保存在表结构定义里的。实际上，表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。

MyISAM 引擎的自增值保存在数据文件中。

innodb中是保存在内存中，在mysql8.0之后将自增值保存在redo log中。可以依靠这个重启

2.自增主键不连续的原因：

​    1.唯一键冲突是导致自增主键 id 不连续的第一种原因

​	2.事务回滚【主键不回退】

​    3.自增主键的批量申请

**深层次原因是，不判断自增主键是否已存在和减少加锁的时间范围和粒度->为了更高的性能->自增主键不能回退->自增主键不连续。**

#### 自增ID用完怎么办？

1. 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。
2. row_id【mysql自己为我们生成的】 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。
3. Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。【XID是mysql在事务中 redo log和binlog相配合的时候使用的】
4. InnoDB 的 max_trx_id【事务ID】 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。
5. thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。



### 2.普通索引和唯一索引的区别

#### 1.查询过程

select id from T where k=5

普通索引：检索到k = 5的节点后，会继续检索后面的节点，知道检索到不是k=5为止，

唯一索引：检索到k=5后，立即返回，因为是唯一的索引节点。

普通索引会多检索一次，几乎没有影响。因为InnoDB的数据是按照数据页为单位进行读写的，需要读取数据时，并不是直接从磁盘读取记录，而是先把数据页读到内存，再去数据页中检索。

一个数据页默认16KB，对于整型字段，一个数据页可以放近千个key，除非要读取的数据在数据页的最后一条记录，就需要再读一个数据页，这种情况很少，对CPU的消耗基本可以忽略了。

总结：在查询过程中，普通索引和唯一索引的差别是微乎其微的

#### 2.更新过程

第一种情况

更新操作在**change buffer内存中有数据时**： 1.唯一索引和普通索引都直接在内存修改

第二种情况：

更新操作在**change buffer内存中没有数据时**：

对于唯一索引 ：将数据页从磁盘读入内存，判断是否唯一，再更新数据页。【关键  是需要判断唯一性】

对于普通索引：直接把更新的数据写在change buff 中就可以了【普通索引是可以重复的】

3.redo log和change buffer的区别

```mysql
mysql> insert into t(id,k) values(id1,k1),(id2,k2);
```

其中K1已经在数据库中，K2不在数据库

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201222135944310.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0x1UWlhb1lh,size_16,color_FFFFFF,t_70#pic_center)

这条更新语句做了以下操作：
1、page1在内存中，直接更新内存，直接把数据插入到表T指定位置。
2、page2 不在内存中，就在change buffer记录一下“我要往page2插入一行”这个操作。
3、将上述两个操作记入redo log中（图中3和4），包含了数据的变更和change buffer的变更。

这样的一个事务，写了两处内存（直接在内存更新和在内存中的change buffer记录），然后写了一次磁盘（两次操作合在一起写了一次磁盘中redo log）

所以电脑异常重启时，change buffer不会丢失。
因为我们更新数据时，虽然只更新内存中的change buffer，但是在事务提交的时候，我们把change buffer中的操作记录也提交到了redo log中，所以崩溃恢复的时候，change buffer也能找回来。

**redo log主要节省的是写磁盘IO消耗（可以转成IO顺序写），而change buffer 主要节省的是随机读取IO的磁盘消耗，其实随机的写这个缓冲也是有帮助的。**

### 3.mysql是怎么保证主备一致的？

在实际生产中一般使用的是主备切换架构。【M-S其中有一个只能作为备库【只能用来读】】

<img src="https://static001.geekbang.org/resource/image/20/56/20ad4e163115198dc6cf372d5116c956.png" alt="img" style="zoom:40%;" />

​                                           【主备切换图-双M结构】节点 A 和 B 之间总是互为主备关系

好处： 切换的是时候不用修改主备关系。

坏处：会产生循环复制问题。【A的binlog发送给B执行，B执行完 又发给A执行 一直循环下去】

 解决办法：

​		1. 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；

​        2.一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；

​       3.每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。

**注**：主备关系里面，备库主动连接，之后的 binlog 发送是主库主动推送的。之所以这么设计也是为了效率和实时性考虑，毕竟靠备库轮询，会有时间差。

**主备是怎么保证一致的？**

主要是通过binlog日志来实现的，

 binlog有三种格式：**1.statement格式**【记录原始sql语句】 缺点是 可能会导致不一致。可能在主库中的操作索引是a。而在备库中操作的索引是b

​								2.row格式【会记录每次操作后每行记录的变化】缺点是：占用空间，耗费IO，影响执行速度

​                            3.mix格式，是上面两个的混合。 一般在生产中使用的是row。

### 4.主备延时问题

https://blog.csdn.net/mingongge/article/details/90310672

在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。

多线程复制原理：

  <img src="https://static001.geekbang.org/resource/image/bc/45/bcf75aa3b0f496699fd7885426bc6245.png" alt="img" style="zoom:50%;" />

coordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的

coordinator 在分发 需要满足两个要求：

​		1.不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。

​        2.同一个事务不能被拆开，必须放到同一个 worker 中。

**多线程并行复制策略**：

   **1.按表分发策略**：会存在跨表问题 就需要将多个表一起考虑。每一个worker线程都会存一个hash表

​    hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。

缺点：

这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。但是，如果碰到热点表，比如所有的更新事务都会涉及到某一个表的时候，所有事务都会被分配到同一个 worker 中，就变成单线程复制了。

**2.按行分发策略：**

​    事务 hash 表中还需要考虑唯一键，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。

​	相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。你可能也发现了，这两个方案其实都有一些约束条件：

**MySQL 5.6 版本的并行复制策略:**

​     	支持了并行复制，只是支持的粒度是按库并行。构建hash值 只需要库名，不要binlog的格式

但是，如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了

**MysQl5.7的并行复制策略**：

 两阶段提交的过程：

  <img src="https://static001.geekbang.org/resource/image/5a/28/5ae7d074c34bc5bd55c82781de670c28.png" alt="img" style="zoom:40%;" />

MySQL 5.7 并行复制策略的思想是：

同时处于 prepare 状态的事务，在备库执行时是可以并行的；

处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。

**mysql5.7.22的并行复制策略：**

1. COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。

2. WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。

3. WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。

### 5.mysql高可用方案，主库出问题，从库切换问题？

<img src="https://static001.geekbang.org/resource/image/aa/79/aadb3b956d1ffc13ac46515a7d619e79.png" alt="img" style="zoom:50%;" />

​                                                                        【一主多从的基本结构】

虚线箭头表示的是主备关系，也就是 A 和 A’互为主备， 从库 B、C、D 指向的是主库 A。一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。

**问题：主库故障后的主备切换问题**

之前的结局方案是？B,C,D找到的A'[成为新的主库]的同步精确。这样会导致错误，插入的数据唯一键冲突或者删除的数据不存在。【因为A‘成为新的主库时 会有延时问题】 遇到错误会直接跳过。【这两个错误并不会影响】

**具体的解决方法是：GTID【全局事务ID】**

每个 MySQL 实例都维护了一个 GTID 集合，用来对应“这个实例执行过的所有事务”。

具体过程：

1. 实例 B 指定主库 A’，基于主备协议建立连接。

2. 实例 B 把 set_b 发给主库 A’。

3. 实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。

​       a.  如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；

​        b. 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；

4. 之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。

### 6.读写分离的问题？

1. 对于数据一致性要求比较高的情况，强制走主库

2. 主库更新后，读从库之前先 sleep 一下。具体的方案就是，类似于执行一条 select sleep(1) 命令。【这样从库很大概率能拿到新的数据】 体验不好

3. 判断主备无延迟方案

    1.每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。

​        2.对比位点确保主备无延迟：备库读到主库最新点的位置，和备库执行的最新点的位置  保持一致。

​		3.GTID 集合确保主备无延迟：主备的GTID集合一样

​    4.半同步方案：一个在主库中的事务。需要在所有从库【或者一个从库】中全部更新，才返回给客户端。这样的话性能低。

​     5.GTID方案：

​       GTID 的执行流程就变成了：

1. trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；

2. 选定一个从库执行查询语句；

3. 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；

4. 如果返回值是 0，则在这个从库执行查询语句；否则，到主库执行查询语句。

总结：不管要用什么方法 都要在一致性和可用性 保持平衡。【不可能总是保持强一致性的【必然会带来性能的下降】】

### 7.日志和索引问题

<img src="https://static001.geekbang.org/resource/image/ee/2a/ee9af616e05e4b853eba27048351f62a.jpg" alt="img" style="zoom:33%;" />

如果A出现问题。由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库

对于B  也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？

1. 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；

2. 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：

   a. 如果是，则提交事务；

   b. 否则，回滚事务。这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。

时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交

**问题1 ：redo log 和 binlog 是怎么关联起来的**?

回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log

如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；

如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。

**问题2 只是用redo log或者binlog 在两阶段提交是行不行？**

不行。因为redo log是重做日志。写完之后重头在写，是不能归档的。

​        binlog是不支持数据恢复能力的。

### 8.count(*) count(1) count(id)

1、执行效果上：  
 count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL  

count(1)包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL  

 count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。

2、执行效率上：  
 列名为主键，count(列名)会比count(1)快  

 列名不为主键，count(1)会比count(列名)快  

如果表多个列并且没有主键，则 count（1） 的执行效率优于 count（*）  

 如果有主键，则 select count（主键）的执行效率是最优的  

  如果表只有一个字段，则 select count（*）最优。

### 9.sharding--jdbc的执行原理

```mysql
当Sharding-JDBC接受到一条SQL语句时，会陆续执行 SQL解析 => 查询优化 => SQL路由 => SQL改写 => SQL执行 => 结果归并 ，最终返回执行结果
```

1.sql解析：词法解析器用于将SQL拆解为不可再分的原子符号，称为Token

2.sql路由：SQL路由就是把针对`逻辑表`【就是数据库拆分之后的总称】的数据操作映射到对数据结点操作的过程

```中文
1.标准路由：它的适用范围是不包含关联查询或仅包含绑定表之间关联查
2.笛卡尔路由：无法根据绑定表定位分片规则，非绑定表之间采用笛卡尔积的规则
3.全库表路由：会对遍历数据库中的所有表，逐一匹配
```

3.sql改写：逻辑SQL改写为在真实数据库中可以正确执行的SQL。

4.SQL执行：执行具体的sql语句

```中文
内存限制模式：使用此模式的前提是，Sharding-JDBC对一次操作所耗费的数据库连接数量不做限制。 如果实际执行的SQL需要对某数据库实例中的200张表做操作，则对每张表创建一个新的数据库连接，并通过多线程的方式并发处理，以达成执行效率最大化。
连接限制模式：Sharding-JDBC严格控制对一次操作所耗费的数据库连接数量。就是对每一个数据库的只创建一个唯一的连接。
```

5.结果合并：将从各个数据节点获取的多数据结果集，组合成为一个结果集并正确的返回至请求客户端

### 10.mysql中使用的LRU算法和怎么优化？

LRU：就是淘汰最久未使用的数据

1.MySQL 在查询数据时，对于 InnoDB 存储引擎而言，会先将磁盘上的数据以页为单位，先将数据页加载进内存，然后以缓存页的形式存放在「Buffer Pool」中。Buffer Pool 是 InnoDB 的一块内存缓冲区，在 MySQL 启动时，会按照配置的缓存页的大小，将 Buffer Pool 缓存区初始化为许多个缓存页，默认情况下，缓存页大小为 16KB。

2.为什么mysql中不能使用LRU，需要优化？

因为MySQL经常会出现一些一些全表扫描。这会导致将该表的磁盘数据全部加载到缓存页中，这就会导致会导致缓存不够。会淘汰一部分缓存页、这就可能将需要频繁使用的缓存页给淘汰了。这就会导致在后面的一段时间内 缓存的命中率明显降低。 这是后在进行查询的时候就重新读取磁盘。发生磁盘IO。性能下降。

3.mysql中的预读？

预读是 InnoDB 引擎的一个优化机制，当你从磁盘上读取某个数据页，InnoDB 可能会将与这个数据页相邻的其他数据页也读取到 Buffer Pool 中【因为INNodb磁盘读取是随机读取的，性能差。当你读取一个数据也的数据页的时候，会将后面几个相邻的数据一页也放到缓存中】

4.mysql对LRU做的优化？

1.冷热分离

对数据进行冷热分离，将 LRU 链表分成两部分，一部分用来存放冷数据，也就是刚从磁盘读进来的数据，另一部分用来存放热点数据，也就是经常被访问到数据。默认冷数据占占链表的3/8.

 【当从磁盘读取数据页后，会先将数据页存放到 LRU 链表冷数据区的头部，如果这些缓存页在 1 秒之后被访问，那么就将缓存页移动到热数据区的头部；如果是 1 秒之内被访问，则不会移动，缓存页仍然处于冷数据区中】

2.LRU链表的极致优化

实际上，MySQL 在冷热分离的基础上还做了一层优化。

当一个缓存页处于热数据区域的时候，我们去访问这个缓存页，这个时候我们真的有必要把它移动到热点数据区域的头部吗？

从代码的角度来看，将链表中的数据移动到头部，实际上就是修改元素的指针指向，这个操作是非常快的。但是为了安全起见，在修改链表的时候，我们需要对链表加上锁，否则容易出现并发问题。

当并发量大的时候，因为要加锁，会存在锁竞争，每次移动显然效率就会下降。因此 MySQL 针对这一点又做了优化，如果一个缓存页处于热数据区域，且在热数据区域的前 1/4 区域（注意是热数据区域的 1/4，不是整个链表的 1/4），那么当访问这个缓存页的时候，就不用把它移动到热数据区域的头部；如果缓存页处于热数据的后 3/4 区域，那么当访问这个缓存页的时候，会把它移动到热数据区域的头部。
